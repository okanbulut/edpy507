---
title: "Classical Test Theory (CTT)"
output:
  html_document:
    toc: TRUE
bibliography: [mybib.bib, packages.bib]
csl: apa.csl
---

```{r setup, include = FALSE}
#Setup knitr
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, warning = FALSE, background = "gray85",
                      message = FALSE, fig.width=8, fig.height=6, comment = NA,
                      fig.align = 'center')

suppressWarnings({
  library("rmarkdown")
  library("fontawesome")
  library("kableExtra")
  library("emo")
  
  # Required packages
  library("dplyr")
  library("car")
  library("skimr")
  library("DataExplorer")
  library("ggcorrplot")
  library("psych")
  library("CTT")
  library("ShinyItemAnalysis")
  library("QME")
  library("rmarkdown")
})

# automatically create a bib database for R packages
knitr::write_bib(x = c(.packages()), file = "packages.bib")
```

***

# Example 1: The Need for Cognition Scale

**Need for cognition**, or shortly NFC, is a psychological latent trait defined as the desire to engage in cognitively challenging tasks and effortful thinking [@nfc-cacioppo]. Individuals with high levels of NFC tend to seek, acquire, think about, and reflect on information, whereas individuals with low levels of NFC tend to avoid detailed information about the world and find cognitively complex tasks stressful [@nfc-cacioppo; @nfc-chiesi]. To measure the latent trait of NFC, Cacioppo and Petty developed the [Need for Cognition Scale](https://centerofinquiry.org/uncategorized/need-for-cognition-scale-wabash-national-study/) [@nfc-cacioppo]. The original scale consists of 34 items that ask individuals to rate the extent to which they agree with statements about the satisfaction they gain from thinking (e.g., The notion of thinking abstractly is appealing to me). @nfc-short also created a shorter form of the scale with 18 items from the original scale (called NFC-18).

\  

Although the NFC Scale is already a well-established tool, we will use it to conduct various psychometric analyses based on Classical Test Theory (CTT) and demonstrate how to collect evidence supporting the reliability and validity of this instrument. The data for our demonstration come from a relatively recent study: "[Thinking in action: Need for Cognition predicts Self-Control together with Action Orientation](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0220282)" [@nfc-grass], focusing on the relationship between NFC and other latent traits (e.g., self-control). To measure NFC, the authors used the German version of the Need for Cognition Scale with 16 items [@nfc-bless]: 


```{r nfc, eval=TRUE, echo=FALSE}
nfc_items <- data.frame(
  Items = 1:16,
  Description = c(
    "Enjoyment of tasks that involve problem-solving",
    "Preference for cognitive, difficult and important tasks",
    "Tendency to strive for goals that require mental effort",
    "Appeal of relying on oneâ€™s thought to be successful (R)",
    "Satisfaction of completing important tasks that required thinking and mental effort",
    "Preference for thinking about long-term projects (R)",
    "Preference for cognitive challenges (R)",
    "Satisfaction on hard and long deliberation (R)",
    "Attitude towards thinking as something one does primarily because one has to (R)",
    "Appeal of being responsible for handling situations that require thinking (R)",
    "Attitude towards thinking as something that is fun (R)",
    "Anticipation and avoiding of situations that may require in-depth thinking (R)",
    "Preference for puzzles to be solved",
    "Preference for complex over simple problems",
    "Preference for understanding the reason for an answer over simply knowing the answer without any background (R)",
    "Preference to know how something works over simply knowing that it works (R)")
)

nfc_items %>%
  kbl() %>%
  kable_styling(bootstrap_options = c("striped", "hover"), font_size = 16) %>%
  footnote(general = "Items marked with (R) were presented in an inverted form.",
           general_title = "Note: ",
           title_format = c("italic"),
           footnote_as_chunk = T)
```

Responses to the items were recorded on a 7-point rating scale from 1 (completely disagree) to 7 (completely agree). However, to calculate total scores in the NFC Scale, we will have to recode the responses as -3 (completely disagree) to +3 (completely agree). @nfc-grass kindly shared their data files and other materials in an open repository: <https://osf.io/wn8xm/>. For the following analyses, we will use a subset of the original data including responses to the NFC Scale, demographic variables, and additional data related self-control etc. This dataset can be downloaded from [**here**](data_and_codes/nfc_data.csv). 

<br>

## Setting up R

To conduct CTT-based analyses, we will use the following R packages:

```{r ctt1, eval=TRUE, echo=FALSE}
pkg_dat <- data.frame(
  Package = c("dplyr", "car",
              "skimr", "DataExplorer", "ggcorrplot",
              "psych", "CTT", "ShinyItemAnalysis", "QME",
              "devtools", "rmarkdown"),
  URL = c("http://CRAN.R-project.org/package=dplyr", 
          "http://CRAN.R-project.org/package=car", 
          "http://CRAN.R-project.org/package=skimr",
          "http://CRAN.R-project.org/package=DataExplorer",
          "http://CRAN.R-project.org/package=ggcorrplot",
          "http://CRAN.R-project.org/package=psych",
          "http://CRAN.R-project.org/package=CTT",
          "http://CRAN.R-project.org/package=ShinyItemAnalysis",
          "https://github.com/zief0002/QME", 
          "http://CRAN.R-project.org/package=devtools",
          "http://CRAN.R-project.org/package=rmarkdown")
)

kbl(pkg_dat, caption = "") %>%
  kable_paper("striped") %>%
  pack_rows("Data Cleaning and Management", 1, 2) %>%
  pack_rows("Exploratory Data Analysis", 3, 5) %>%
  pack_rows("Psychometric Analysis", 6, 9) %>%
  pack_rows("Ancillary Packages", 10, 11)
```

\  

We can install all of the above packages by using the `install.packages()` command in R. Please note that you need to install these packages <u>only once</u>.  

```{r ctt2, eval=FALSE}
# Install all the packages together
install.packages(c("dplyr", "car", "skimr", "DataExplorer", "ggcorrplot",
              "psych", "CTT", "ShinyItemAnalysis", "devtools", "rmarkdown", 
              "chronicle"))

# Or, we could do it one by one. For example:
# install.packages("CTT")
# install.packages("psych")
# and so on...
```

Since the **QME** package [@R-QME] is available on [GitHub](https://github.com/zief0002/QME) instead of CRAN, we will use `install_github` from the **devtools** package to install it.

```{r ctt3, eval=FALSE}
devtools::install_github("zief0002/QME") 
```

After you install the packages properly (i.e., no error messages on your R console), you can use the `library()` command to activate these packages in your R session. 

```{r ctt4, eval=FALSE}
# Activate the packages
library("dplyr")
library("car")
library("skimr")
library("DataExplorer")
library("ggcorrplot")
library("psych")
library("CTT")
library("ShinyItemAnalysis")
library("QME")
library("rmarkdown")
```

Each of these packages comes with several functions. Once you activate a package, you can start using all the functions loaded with that package. To call a particular function from a package, we need to know the function name. For example, we can use the `alpha()` function in the **psych** package to calculate internal consistency values such as coefficient alpha. Since we are going to use multiple functions from different packages, it might be a bit difficult to remember which package each function belongs to. Therefore, I will use the following format in my codes: `packagename::function`. For example, `psych::alpha()` indicates that I am calling the `alpha()` function from the **psych** package.

***

> `r emo::ji("+1")` <span style="color:blue">**NOTE:**</span> Using `::` has two more benefits. First, when we use `::`, we can call a particular function from a package without activating the entire package. For example, `psych::alpha()` allows us to use the `alpha()` function without having to run `library("psych")` beforehand. Second, if two or more packages activated within an R session include a function with the same name, then R only gives us access the function from the most recently activated package. This is called "masking". For example, the **ggplot2** package also has an `alpha()` function. If we first loaded **psych** and then **ggplot2**, the `alpha()` from **ggplot2** would mask the `alpha()` function from **psych**. However, by using `psych::alpha()`, we can still access the `alpha()` function from **psych**.   

***

## Exploratory data analysis

[Exploratory data analysis (EDA)](https://okanbulut.github.io/bigdata/eda.html) refers to the process of performing initial investigations on data in order to detect anomalies (e.g., unexpected values, high levels of missigness), check various assumptions (e.g., normality), and discover interesting patterns. When performing EDA, we often use both statistical and data visualization tools to summarize the data. 

Before we begin the analysis, let's set up our working directory. I created a new folder called "CTT Analysis" on my desktop and put our data ([nfc_data.csv](data_and_codes/nfc_data.csv)) into this folder. You can also create the same folder in a convenient location in your computer and save the path to this folder. Now, we can change our working directory to this new folder:

```{r ctt5, eval=FALSE}
setwd("C:/Users/Okan/Desktop/CTT Analysis")
```

Next, we will import the data into R. Since nfc_data.csv is a comma-separated-values file (see the .csv extension), we will use the `read.csv()` function to read our data into R. We will save the data as "nfc" in R. 

```{r ctt6, eval=FALSE}
nfc <- read.csv("nfc_data.csv", header = TRUE)
```

Using the `head()` function, we can view the first 6 rows of the dataset:

```{r ctt7, eval=FALSE}
head(nfc)
```


```{r ctt8, echo=FALSE}
nfc <- read.csv(paste0(getwd(), "/data_and_codes/nfc_data.csv"), header = TRUE)
paged_table(nfc, options = list(cols.print = 12, rows.print = 6))
```

We can also see the names and types of the variables in our dataset using the `str()` function (which shows us the **str**ucture of the data):

```{r ctt9, echo=TRUE}
str(nfc)
```

The dataset consists of 1209 rows (i.e., participants) and 29 variables (id, age, sex, education, nfc01 to nfc16 representing the responses to the NFC Scale items, and 9 raw scores for other latent traits).

We can obtain a bit more information on the dataset using the `introduce()` and `plot_intro()` functions:

```{r ctt10, echo=TRUE, eval=FALSE}
DataExplorer::introduce(nfc)
```

```{r ctt11, echo=FALSE}
kbl(t(introduce(nfc)), 
    row.names = TRUE, col.names = "", 
    format.args = list(big.mark = ",")) %>%
  kable_styling()
```

The output above gives us a summary of our dataset with additional information on the total number of missing values, total number of observations, and so on. 

```{r ctt12, echo=TRUE}
DataExplorer::plot_intro(nfc)
```

The plot above shows that most of the variables in the dataset are continuous (note that R recognizes Likert-scale items as continuous variables although they are actually ordinal) while there are also some discrete (i.e., categorical) variables (remember the sex and education variables in the dataset). We also see that some of the variables in the dataset have missing values but the proportion of missing data is very small (only 0.023%). Depending on the sample size, missingness > 10% is often concerning as the loss of information due to these missing values is likely to influence the results of our analysis. 

To have a closer look at missing values, we can visualize the proportion of missingness for each variable. The following plot shows that age and sex have some missing values but the proportion of missingness is very small (less than 1%).

```{r ctt13a, echo=TRUE}
DataExplorer::plot_missing(nfc)
```

The **DataExplorer** package also has additional functions to visualize both categorical and continuous variables. The package is using a simpler language to create plots based on the **ggplot2** package in the background. 

```{r ctt13b, echo=TRUE, fig.height=4}
# Categorical variables (bar plots)
DataExplorer::plot_bar(data = nfc[, c("education", "sex")])

# Continuous variables (histogram)
DataExplorer::plot_histogram(data = nfc[, c("age", "preoccupation", "hesitation", "self_control")])

# Continuous variables (boxplot) by a categorical variable
DataExplorer::plot_boxplot(data = nfc[!is.na(nfc$sex), # select cases where sex is not missing
                                      # Select variables of interest
                                      c("sex", "preoccupation", "hesitation", "self_control")], 
                           by = "sex")
```

To organize all the summary statistics into a single report, we could use the `create_report()` function. It runs most functions in **DataExplorer** and outputs a HTML report file.

```{r ctt13c, echo=TRUE, eval=FALSE}
# Drop the id variable so it doesn't get analyzed with the other variables
nfc <- DataExplorer::drop_columns(nfc, "id")

# This code creates a report and saves it into the working directory
DataExplorer::create_report(data = nfc,
                            report_title = "NFC Scale Analysis",
                            output_file = "nfc_report.html")
```

To obtain a detailed summary of the nfc dataset within a single analysis, we can use the `skim()` function. As you can see from the output below, we obtained similar descriptive statistics for the variables in the nfc dataset:

* "Data Summary" shows the number of columns/rows and column types (i.e., variable types)
* "Variable type" tables show a summary of character (i.e., categorical) and numeric (i.e., continuous) variables

In "Variable type: character", we see the number of missing values, complete data rate, the minimum number of characters (e.g., 4 for sex: male) and maximum number of characters (e.g., 6 for sex: female), and the number of unique values (e.g., 2 for sex: male and female) for the variables. 

In "Variable type: numeric", we see the number of missing values, complete data rate, mean, standard deviation, min (p0), 25th percentile (p25), median (p50), 75% percentile (p75), and max (p100) values for the variables.


```{r ctt14, eval=FALSE}
skimr::skim(nfc)
```


```{r ctt15, echo=FALSE, R.options = list(width = 200)}
skimr::skim_without_charts(nfc) %>%
  print()
```

<br>

Before moving to item analysis, we also need to check the correlation among the items to evaluate how strongly the items are associated with each other. We expect the items to be associated with each other up to a certain degree because we assume that the items measure the same latent trait (the construct of NFC in this example). Having weakly-correlated items suggests that some items may **not** be measuring the same latent trait. Having very highly-correlated items (e.g., $r > .95$) suggests that there is some redundancy in the instrument because some items provide us with the same information about the individuals who answered the items.   

In addition, we know that some items in the NFC Scale are negatively-worded and thus responses to these items may be in the opposite direction with the rest of the items. For example, individuals with high NFC are likely to choose "7 = completely agree" for positively-worded items (e.g., "Enjoyment of tasks that involve problem-solving") whereas they are expected to choose "1 = completely disagree" for negatively-worded items (e.g., "Anticipation and avoiding of situations that may require in-depth thinking").

Now, we will create a correlation matrix of the NFC items and review the strength and direction of the relationship among the items. First, we will save the responses as a separate dataset to make our subsequent analyses easier. The items in the nfc dataset are named as nfc01, nfc02, ..., nfc16. That is, they all start with the same prefix: nfc. So, I can use this to select the items more easily. We will use the `select()` function from **dplyr**. `starts_with("nfc")` will help us choose the variables starting with "nfc" as a selection condition. 

```{r ctt16, echo=TRUE}
response <- dplyr::select(nfc, # name of the dataset
                          starts_with("nfc")) # variables to be selected

head(response)
```

Alternatively, we could type each item by one one (which is much more tedious):

```{r ctt17, eval=FALSE}
response <- dplyr::select(nfc, 
                          nfc01, nfc02, nfc03, nfc04, ..., nfc16) 
```

Next, we will compute the correlations among these items. Remember that the NFC items follow an ordinal scale: 1=completely disagree to 7=completely agree. Therefore, instead of traditional Pearson correlation (which can be obtained using the `cor()` function in R), we will use the `polychoric()` function from **psych** to calculate polychoric correlations. The function produces several outcomes but we want to keep `rho`- (i.e., the correlation matrix of the items). 

```{r ctt18, eval=FALSE}
cormat <- psych::polychoric(response)$rho

print(cormat)
```

```{r ctt19, echo=FALSE}
cormat <- polychoric(response)$rho

cormat %>%
  kbl() %>%
  kable_styling(bootstrap_options = c("striped", "condensed"), font_size = 11)
```

One thing that we can see right away is negative values in the correlation matrix, confirming that some items are indeed negatively correlated with each other. However, reviewing the rest of this 16x16 correlation matrix is not necessarily easy. We can't just eyeball the values to evaluate the associations among the items. Therefore, we will create a correlation matrix plot using the **ggcorrplot** package. The package has a function with the same name, `ggcorrplot()`, that transforms a correlation matrix into a nice plot.

```{r ctt20, echo=TRUE, fig.width=9, fig.height=6}
ggcorrplot::ggcorrplot(corr = cormat, # correlation matrix
                       type = "lower", # print only the lower part of the correlation matrix
                       show.diag = TRUE, # show the diagonal values of 1
                       lab = TRUE, # add correlation values as labels
                       lab_size = 3) # Size of the labels
```

There are tons of options to customize the correlation matrix plot (run `?ggcorrplot::ggcorrplot` to see the help page), but this is already a very good visualization for us to evaluate the correlations among the items. We see that several items on the scale (see the blue-coloured boxes) are negatively correlated with the rest of the items. These are the (R) marked items in the NFC Scale (i.e., negatively-worded items). We will go ahead and reverse-code the responses to these items (i.e., 1=completely agree to 7=completely disagree) to put all the items in the same direction. 

We will use the `reverse.code()` function from **psych** for this process. We will create a reverse-coding key where "1" keeps the item the same and "-1" reverse-codes the item. In `nfc_key` below, we type "1" three times (no reverse-coding for the first three items), type "1" for the 4th item (reverse-code the item), type 1 for the 5th item (no reverse-coding), and so on. That is, the values in `nfc_key` correspond to the positions of the items in the `response` dataset. Then, we use `reverse.code()` to apply the key and transform the data (saved as `response_recoded`).

```{r ctt21, echo=TRUE}
# -1 means reverse-code the item
nfc_key <- c(1,1,1,-1,1,-1,-1,-1,-1,-1,-1,-1,1,1,-1,-1)

response_recoded <- psych::reverse.code(
  keys = nfc_key, # reverse-coding key
  items = response, # dataset to be transformed
  mini = 1, # minimum response value
  maxi = 7) # maximum response value
```

Let's see if our transformation worked: 

```{r ctt22, echo=TRUE}
cormat_recoded <- psych::polychoric(response_recoded)$rho

ggcorrplot::ggcorrplot(corr = cormat_recoded,
                       type = "lower", 
                       show.diag = TRUE,
                       lab = TRUE, 
                       lab_size = 3) 
```

We can see in the correlation matrix plot that all the items are now positively correlated. Most correlations are moderate while there also some items (e.g., nfc06) that seem to have low correlations with the other items in the NFC scale. Also, we see that `reverse.code()` changed the names of the reverse-coded items by include "-" at the end (e.g., nfc04-). This is not necessarily a problem. However, if we want to keep the original variable names (i.e., nfc01 to nfc16), we can rename the column names using the `colnames()` function. The following will replace the column names of the transformed data (i.e., `response_recoded`) with the column names of the original response data (i.e., `response`) and then save the dataset as a data frame (the typical data format in R).

```{r ctt23, echo=TRUE, R.options = list(width = 200)}
# Rename the columns
colnames(response_recoded) <- colnames(response)

# Save the data as a data frame
response_recoded <- as.data.frame(response_recoded)

# Preview the first six rows of the data
head(response_recoded)
```

<br>

## Item analysis

Item analysis refers to a comprehensive analysis of individual items on a measurement instrument in terms of descriptive statistics (e.g., mean, standard deviation, min, and max), item-level statistics (e.g., difficulty and discrimination), and their associations with scale-level statistics (e.g., reliability). In R, there are several packages to conduct item analysis on dichotomous items (i.e., 0 or 1) and ordinal items (e.g., Likert-scale items). I will demonstrate three of these packages below:

1. **CTT** [@R-CTT]: The `itemAnalysis()` function runs item analysis and returns a brief but useful table of item statistics. Specifying the dataset to be analyzed (response_recoded) in the `itemAnalysis()` function is enough to run item analysis. In the following example, we will also set two flags for point-biserial correlation (pBisFlag) and biserial correlation (bisFlag). Both of these statistics indicate the discriminatory power of the items. In practice, we prefer both point-biserial correlation and biserial correlation values to be at least 0.2 or larger. So, we will set the flag at 0.2 so that the function shows us (using an "X" sign) the items with discrimination of .2 or less (see more details on the help page via `?CTT::itemAnalysis`).

```{r ctt24, echo=TRUE}
# Run the item analysis and save it as itemanalysis_ctt
itemanalysis_ctt <- CTT::itemAnalysis(items = response_recoded, pBisFlag = .2, bisFlag = .2)

# Print the item report
itemanalysis_ctt$itemReport
```

In the output above, "itemMean" is the average response value for each item (which is not necessarily useful given that our items are ordinal), "pBis" and "bis" refer to point-biserial and bi-serial correlations respectively, "alphaIfDeleted" indicates how the reliability of the instrument would change if each item were to be removed (we will discuss reliability in the next section), and the last two columns ("lowPBis" and "lowBis") are the columns where we would see flags (i.e., X marks) if the values are less than 0.2. In this example, all the items seem to have pBis and bis values larger than 0.2 and thus there are no flagged items. 

<br>

2. **psych** [@R-psych]: The `alpha()` function runs item analysis and returns a detailed output with both item-level and scale-level statistics. To use the function, we need to specify the response dataset to be analyzed (i.e., `x = response_recoded`). The function also involves other arguments (e.g., `na.rm = TRUE` to remove missing values and find pairwise correlations), but the default values for these arguments are sufficient to conduct item analysis (see more details on the help page via `?psych::alpha`).

```{r ctt25, echo=TRUE}
# Run the item analysis and save it as itemanalysis_psych
itemanalysis_psych <- psych::alpha(x = response_recoded)

# Print the results
itemanalysis_psych
```

The first part of the output shows the results of reliability analysis but we will discuss these results in the next section. For now, let's focus on "Item statistics" and "Non missing response frequency for each item". 

**Item statistics:** The table shows the number of valid responses for each item (n), correlations between the items and the total score from the instrument (raw.r) where the item itself is included in the calculation of the total score, correlations between the items and the total score if the items were all standardized (std.r), correlations between the items and the total score corrected for both item overlap and scale reliability (r.cor), correlations between the items and the total score where the item of interest is *not* included in the calculation of the total score (r.drop), average response values (mean), and standard deviation of response values (sd). Compared with raw.r, r.cor and r.drop are better indicators of item discrimination as they indicate the relationship between each item and the rest of the items without contaminating the total score. We want r.cor and r.drop values to be larger than 0.2 for each item.  

**Non missing response frequency for each item:** The table shows what percentages of respondents selected each response option of the each of the items. Each item in the NFC Scale have response options of 1 to 7 and thus we see each of these response options and the missing response in the last column. This table helps us check the distribution of response options and whether all or almost all respondents selected the same response options for some items (which lowers the reliability). In our example, we can see that the lowest response option (i.e., 1) was selected by a very low proportion of respondents whereas the middle and upper response categories (i.e., 4, 5, 6, and 7) were selected by much more respondents.  

<br>

3. **ShinyItemAnalysis** [@R-ShinyItemAnalysis]: The `ItemAnalysis()` function runs item analysis and returns much more detailed output compared with those of **CTT** and **psych**. The function has so many options that allows users to customize the item analysis report in several ways (see more details on the help page via `?ShinyItemAnalysis::ItemAnalysis`). Also, using the `startShinyItemAnalysis()` function, we can use the interactive version of `ItemAnalysis()` where we can import the data and select the analysis to be conducted using a nice user interface based on the **shiny** package (for examples of interesting **shiny** applications, see <https://shiny.rstudio.com/>).

```{r ctt26a, echo=TRUE, R.options = list(width = 100)}
# Run the item analysis and save it as itemanalysis_shiny
itemanalysis_shiny <- ShinyItemAnalysis::ItemAnalysis(Data = response_recoded)

# Print the results
itemanalysis_shiny
```

In the output above, there is tons of information regarding the items, but the ones we should review are: 

* Difficulty: A standardized difficulty value between 0 and 1 based on the average score of the item divided by its range
* Mean: Average item score
* SD: Standard deviation of the item score
* RIT: Correlations between item scores and the total test score (same as r.raw from **psych**)
* RIR: Correlations between item scores and the total test score without the given item (same as r.drop from **psych**)

The same package also includes a `DDplot()` function to visualize difficulty and discrimination statistics together. For the `discrim` argument, we will use "RIR" to plot *corrected* item discrimination values (alternatively, we could use "RIT" for uncorrected discrimination values or "none" to plot only difficulty values). 

```{r ctt26b, echo=TRUE, R.options = list(width = 100)}
# Create a difficulty and discrimination (DD) plot
ShinyItemAnalysis::DDplot(Data = response_recoded, discrim = "RIR")
```

<br>

## Reliability

### Split-half reliability

```{r ctt27, echo=TRUE}
psych::splitHalf(r = response_recoded)
```

### Internal consistency

```{r ctt28, echo=TRUE}
# Print the results
itemanalysis_ctt
```

```{r ctt29, echo=TRUE}
reliability_qme <- QME::analyze(response_recoded, id = FALSE, d = 3)
reliability_qme
```

### Spearman-Brown prophecy formula

```{r ctt30, echo=TRUE}
# old reliability is 0.87, if the measure is shortened
# by a factor of 1/2, the reliability of new test is:
CTT::spearman.brown(0.87, 1/2, "n")
```

```{r ctt31, echo=TRUE}
# old relibility is 0.87, if we want a new measure to
# be 0.95, the new test length is:
n <- CTT::spearman.brown(0.87, 0.90, "r")

round(n$n.new * 16, 0)
```

<br>

## Criterion-related validity

xxx

***

# Example 2: A Multiple-Choice Exam

xxx

<br>

# References
